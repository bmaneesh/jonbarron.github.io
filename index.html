<!DOCTYPE HTML>
<html lang="en">
  <head>
    <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

    <title>Maneesh Bilalpur</title>

    <meta name="author" content="Maneesh Bilalpur">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <link rel="shortcut icon" href="images/favicon/favicon.ico" type="image/x-icon">
    <link rel="stylesheet" type="text/css" href="stylesheet.css">
    
  </head>

  <body>
    <table style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
      <tr style="padding:0px">
        <td style="padding:0px">
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr style="padding:0px">
              <td style="padding:2.5%;width:63%;vertical-align:middle">
                <p class="name" style="text-align: center;">
                  Maneesh Bilalpur
                </p>
                <p>
		I'm a PhD candidate at the University of Pittsburgh's <a href="http://sci.pitt.edu">School of Computing and Information</a>, where I work on Multimodal Machine Learning. I am supervised by Prof. <a href="https://www.jeffcohn.net/">Jeff Cohn</a>.
		My interests include utilizing facial expressions, voice prosody, body pose, and speech for applications in affective computing. I am also curious about how these multimodal behaviors shape day-to-day human communication.
    </p>
    <p>
    Prior to my PhD, I've worked at a computer vision data annotation startup <a href="http://playment.io/">Playment</a> on semantic segmentation and object detection.
		My Masters of Science thesis was supervised by Prof. <a href="https://www.ramsubramanian.net/">Ramanathan Subramanian</a>, and Prof. <a href="https://www.comp.nus.edu.sg/~mohan/">Mohan Kankanhalli</a> at <a href="https://www.iiit.ac.in/">iiit hyderabad</a>.
                </p>
                <p style="text-align:center">
                  <a href="mailto:likelyworking@gmail.com">Email</a> &nbsp;/&nbsp;
                  <a href="data/maneesh-cv.pdf">CV</a> &nbsp;/&nbsp;
                  <a href="https://scholar.google.co.in/citations?user=QlnoVnwAAAAJ">Scholar</a> &nbsp;/&nbsp;
                  <a href="https://twitter.com/maneeshbilalpur">Twitter</a> &nbsp;/&nbsp;
                  <a href="https://www.linkedin.com/in/maneesh-bilalpur/">LinkedIn</a> &nbsp;/&nbsp;
                  <a href="https://github.com/bmaneesh/">Github</a>
                </p>
              </td>
              <td style="padding:2.5%;width:37%;max-width:37%">
                <a href="images/maneesh_profile.jpg"><img style="width:100%;max-width:100%;object-fit: cover; border-radius: 50%;" alt="profile photo" src="images/maneesh_profile.jpg" class="hoverZoomLink"></a>
              </td>
            </tr>
          </tbody></table>

<!-- ──────────────────────────────────────────────────────────────────────── -->
<!-- 2) AWARDS AND RECOGNITION SECTION -->
<!-- ──────────────────────────────────────────────────────────────────────── -->
<div style="width:100%; max-width:800px; margin:24px auto 0; padding:0 16px;">
  <h2>News</h2>
  <ul style="margin-top:8px; padding-left:1.2em; line-height:1.5em;">
    <li>Presented my dissertation work at the Doctoral Consortium at FG 2025.</li>
    <li>Awarded the Provost's Dissertation Completion Fellowship for Fall 2025 at Pitt.</li>
    <li>Delivered a guest lecture on Multimodal LLMs for the CS 2750 course at Pitt.</li>
    <li>Received the Oustanding Reviewer Award at FG 2024.</li>
</ul>
</div>


          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
              <tr>
              <td style="padding:16px;width:100%;vertical-align:middle">
                <h2>Research</h2>
                <p>
                  My experience of multimodal machine learning research spans multiple domains including Computer Vision, Speech Processing, and Natural Language Processing. I also tinker with statistics (mixed-effects) for hypothesis testing in human behavior. Here are some papers that I have worked on. The exhaustive list can be found on my <a href="https://scholar.google.co.in/citations?user=QlnoVnwAAAAJ&hl=en&oi=ao">google scholar profile</a>.
                </p>
              </td>
            </tr>
          </tbody></table>
          
          <table style="width:100%;border:0px;border-spacing:0px 10px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <!-- <table style="width:100%;border:0px;border-spacing:0px 10px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody> -->


    <!-- <tr onmouseout="bolt3d_stop()" onmouseover="bolt3d_start()"  bgcolor="#ffffd0">
      <td style="padding:16px;width:20%;vertical-align:middle">
        <div class="one">
          <div class="two" id='bolt3d_image'><video  width=100% height=100% muted autoplay loop>
          <source src="images/bolt3d.mp4" type="video/mp4">
          Your browser does not support the video tag.

          </video></div>
          <img src='images/bolt3d.jpg' width="160">
        </div>
        <script type="text/javascript">
          function bolt3d_start() {
            document.getElementById('bolt3d_image').style.opacity = "1";
          }

          function bolt3d_stop() {
            document.getElementById('bolt3d_image').style.opacity = "0";
          }
          bolt3d_stop()
        </script>
      </td>
      <td style="padding:8px;width:80%;vertical-align:middle">
        <a href="https://szymanowiczs.github.io/bolt3d">
          <span class="papertitle">Bolt3D: Generating 3D Scenes in Seconds</span>
        </a>
        <br>
        <a href="https://szymanowiczs.github.io/">Stanislaw Szymanowicz</a>,
        <a href="https://jasonyzhang.com">Jason Y. Zhang</a>,
        <a href="https://pratulsrinivasan.github.io">Pratul Srinivasan</a>,
        <a href="https://ruiqigao.github.io">Ruiqi Gao</a>,
        <a href="https://github.com/ArthurBrussee">Arthur Brussee</a>,
        <a href="https://holynski.org">Aleksander Holynski</a>,
        <a href="https://ricardomartinbrualla.com">Ricardo Martin-Brualla</a>,
		<strong>Jonathan T. Barron</strong>,
        <a href="https://henzler.github.io">Philipp Henzler</a>
        <br>
        <em>arXiv</em>, 2025
        <br>
        <a href="https://szymanowiczs.github.io/bolt3d">project page</a>
        /
        <a href="https://szymanowiczs.github.io/bolt3d">arXiv</a>
        <p></p>
        <p>
		By training a latent diffusion model to directly output 3D Gaussians we enable fast (~6 seconds on a single GPU) feed-forward 3D scene generation.
        </p>
      </td>
    </tr> -->

    <!-- <tr onmouseout="r2r_stop()" onmouseover="r2r_start()">
      <td style="padding:16px;width:20%;vertical-align:middle">
        <div class="one">
          <div class="two" id='r2r_image'><video  width=100% muted autoplay loop>
          <source src="images/r2r.mp4" type="video/mp4">
          Your browser does not support the video tag.
          </video></div>
          <img src='images/r2r.jpg' width=100%>
        </div>
        <script type="text/javascript">
          function r2r_start() {
            document.getElementById('r2r_image').style.opacity = "1";
          }

          function r2r_stop() {
            document.getElementById('r2r_image').style.opacity = "0";
          }
          r2r_stop()
        </script>
      </td>
      <td style="padding:8px;width:80%;vertical-align:middle">
        <a href="https://relight-to-reconstruct.github.io/">
          <span class="papertitle">Generative Multiview Relighting for
3D Reconstruction under Extreme Illumination Variation</span>
        </a>
        <br>
        <a href="https://hadizayer.github.io/">Hadi Alzayer</a>,
        <a href="https://henzler.github.io/">Philipp Henzler</a>,
				<strong>Jonathan T. Barron</strong>, 
        <a href="https://jbhuang0604.github.io/">Jia-Bin Huang</a>,
        <a href="https://pratulsrinivasan.github.io/">Pratul P. Srinivasan</a>, 
        <a href="https://dorverbin.github.io/">Dor Verbin</a>
        <br>
        <em>CVPR</em>, 2025 &nbsp <font color=#FF8080><strong>(Highlight)</strong></font>
        <br>
        <a href="https://relight-to-reconstruct.github.io/">project page</a>
        /
        <a href="https://arxiv.org/abs/2412.15211">arXiv</a>
        <p></p>
        <p>
				Images taken under extreme illumination variation can be made consistent with diffusion, and this enables high-quality 3D reconstruction.
        </p>
      </td>
    </tr> -->

            <tr>
              <td style="padding:8px;width:20%;vertical-align:middle">
                <img src="images/MB_papers/Cariola_journal.JPG" alt="blind-date" width="160" height="160" style="object-fit: contain;">
              </td>
              <td style="padding:8px;width:80%;vertical-align:middle">
                <a href="https://www.sciencedirect.com/science/article/pii/S0165032724013570">
                  <span class="papertitle">Language use in depressed and non-depressed mothers and their adolescent offspring</span>
                </a>
                <br>
                Laura A Cariola, Lisa B Sheeber, Nicholas Allen, <strong>Maneesh Bilalpur</strong>, Timothy Bird, Saurabh Hinduja, Louis-Philippe Morency, and Jeffrey F Cohn
                <br>
                <em>Journal of Affective Disorders (Impact Factor: 4.9)</em>, 2024
              </td>
            </tr>

            <tr>
              <td style="padding:8px;width:20%;vertical-align:middle">
                <img src="images/MB_papers/pyafar_demo.gif" alt="blind-date" width="160" height="160" style="object-fit: contain;">
              </td>
              <td style="padding:8px;width:80%;vertical-align:middle">
                <a href="https://brosdocs.net/fg2024/337.pdf">
                  <span class="papertitle">Expanding PyAFAR: A Novel Privacy-Preserving Infant AU Detector</span>
                </a>
                <br>
                Itir Onal Ertugrul, Saurabh Hinduja, <strong>Maneesh Bilalpur</strong>, Daniel S Messinger, and Jeffrey F Cohn
                <br>
                <em>IEEE FG</em>, 2024
              </td>
            </tr>


            <tr>
              <td style="padding:8px;width:20%;vertical-align:middle">
                <img src="images/MB_papers/AAAI2024.jpg" alt="clean-usnob" width="160" height="160" style="object-fit: contain;">
              </td>
              <td style="padding:8px;width:80%;vertical-align:middle">
                <a href="https://ceur-ws.org/Vol-3649/Paper16.pdf">
                  <span class="papertitle">Learning to generate context-sensitive backchannel smiles for embodied ai agents with applications in mental health dialogues</span>
                </a>
                <br>
                <strong>Maneesh Bilalpur</strong>, Mert Inan, Dorsa Zeinali, Jeffrey F Cohn, and Malihe Alikhani
                <br>
                <em>AAAI Workshop</em>, 2024
              </td>
            </tr>

            <!-- <tr>
              <td style="padding:8px;width:20%;vertical-align:middle">
                <img src="images/MB_papers/temporal_physiology.JPG" alt="clean-usnob" width="160" height="160" style="object-fit: contain;">
              </td>
              <td style="padding:8px;width:80%;vertical-align:middle">
                <a href="https://d197for5662m48.cloudfront.net/documents/publicationstatus/170591/preprint_pdf/e3469a1f0ac3fdcd38f7ae27027a8cab.pdf">
                  <span class="papertitle">Multimodal Temporal Modeling of Emotion using Physiological Signals</span>
                </a>
                <br>
                Saurabh Hinduja, <strong>Maneesh Bilalpur</strong>, Liza Jivnani, and Shaun Canavan
                <br>
                <em>ArXiv</em>, 2024
              </td>
            </tr> -->

            <tr>
              <td style="padding:8px;width:20%;vertical-align:middle">
                <img src="images/MB_papers/argument_mining.JPG" alt="clean-usnob" width="160" height="160" style="object-fit: contain;">
              </td>
              <td style="padding:8px;width:80%;vertical-align:middle">
                <a href="https://aclanthology.org/2023.argmining-1.18/">
                  <span class="papertitle">Argumentative stance prediction: An exploratory study on multimodality and few-shot learning</span>
                </a>
                <br>
                Arushi Sharma*, Abhibha Gupta*, and <strong>Maneesh Bilalpur*</strong> (*equal contributions)
                <br>
                <em>EMNLP Workshop on Argument Mining</em>, 2023
              </td>
            </tr>

            <td style="padding:8px;width:20%;vertical-align:middle">
              <img src="images/MB_papers/TPOT_handcrafted.png" alt="clean-usnob" width="160" height="160" style="object-fit: contain;">
            </td>
            <td style="padding:8px;width:80%;vertical-align:middle">
              <a href="https://dl.acm.org/doi/pdf/10.1145/3577190.3614136">
                <span class="papertitle">SHAP-based Prediction of Mother's History of Depression to Understand the Influence on Child Behavior</span>
              </a>
              <br>
              <strong>Maneesh Bilalpur</strong>, Saurabh Hinduja, Laura Cariola, Lisa Sheeber, Nicholas Allen, Louis-Philippe Morency, and Jeffrey F Cohn
              <br>
              <em>ACM ICMI</em>, 2023
            </td>
          </tr>

          <tr>
            <td style="padding:8px;width:20%;vertical-align:middle">
              <img src="images/MB_papers/pyafar2024.JPG" alt="clean-usnob" width="160" height="160" style="object-fit: contain;">
            </td>
            <td style="padding:8px;width:80%;vertical-align:middle">
              <a href="https://www.jeffcohn.net/wp-content/uploads/2023/08/ACII_2023_paper_242-2.pdf">
                <span class="papertitle">PyAFAR: Python-based automated facial action recognition library for use in infants and adults</span>
              </a>
              <br>
              Saurabh Hinduja, Itir Onal Ertugrul, <strong>Maneesh Bilalpur</strong>, Daniel S Messinger, and Jeffrey F Cohn
              <br>
              <em>IEEE ACII Demo</em>, 2023
            </td>
          </tr>

          <tr>
            <td style="padding:8px;width:20%;vertical-align:middle">
              <img src="images/MB_papers/infant_afar.JPG" alt="clean-usnob" width="160" height="160" style="object-fit: contain;">
            </td>
            <td style="padding:8px;width:80%;vertical-align:middle">
              <a href="https://link.springer.com/article/10.3758/s13428-022-01863-y">
                <span class="papertitle">Infant AFAR: Automated facial action recognition in infants</span>
              </a>
              <br>
              Itir Onal Ertugrul, Yeojin Amy Ahn, <strong>Maneesh Bilalpur</strong>, Daniel S Messinger, Matthew L Speltz, and Jeffrey F Cohn
              <br>
              <em>Behavior Research Methods</em>, 2023
            </td>
          </tr>

          <tr>
            <td style="padding:8px;width:20%;vertical-align:middle">
              <img src="images/MB_papers/TPOT_handcrafted.png" alt="clean-usnob" width="160" height="160" style="object-fit: contain;">
            </td>
            <td style="padding:8px;width:80%;vertical-align:middle">
              <a href="https://www.jeffcohn.net/wp-content/uploads/2022/10/FG2023_camera_ready.pdf">
                <span class="papertitle">Multimodal Feature Selection for Detecting Mothers' Depression in Dyadic Interactions with their Adolescent Offspring</span>
              </a>
              <br>
              <strong>Maneesh Bilalpur</strong>, Saurabh Hinduja, Laura A Cariola, Lisa B Sheeber, Nick Alien, László A Jeni, Louis-Philippe Morency, and Jeffrey F Cohn
              <br>
              <em>IEEE FG</em>, 2023
            </td>
          </tr>

          <tr>
            <td style="padding:8px;width:20%;vertical-align:middle">
              <img src="images/MB_papers/ballistic_timing.JPG" alt="clean-usnob" width="160" height="160" style="object-fit: contain;">
            </td>
            <td style="padding:8px;width:80%;vertical-align:middle">
              <a href="https://www.jeffcohn.net/wp-content/uploads/2022/08/ACII2022_Ballistic.pdf">
                <span class="papertitle">Ballistic Timing of Smiles is Robust to Context, Gender, Ethnicity, and National Differences</span>
              </a>
              <br>
              <strong>Maneesh Bilalpur</strong>, Saurabh Hinduja, Kenneth Goodrich, and Jeffrey F Cohn
              <br>
              <em>IEEE ACII</em>, 2022
            </td>
          </tr>

          <tr>
            <td style="padding:8px;width:20%;vertical-align:middle">
              <img src="images/MB_papers/ICMI2018.JPG" alt="clean-usnob" width="160" height="160" style="object-fit: contain;">
            </td>
            <td style="padding:8px;width:80%;vertical-align:middle">
              <a href="https://arxiv.org/pdf/1708.08735">
                <span class="papertitle">Gender and emotion recognition with implicit user signals</span>
              </a>
              <br>
              <strong>Maneesh Bilalpur</strong>, Seyed Mostafa Kia, Manisha Chawla, Tat-Seng Chua, and Ramanathan Subramanian
              <br>
              <em>ACM ICMI</em>, 2017
            </td>
          </tr>

          <tr>
            <td style="padding:8px;width:20%;vertical-align:middle">
              <img src="images/MB_papers/ACII2027.JPG" alt="clean-usnob" width="160" height="160" style="object-fit: contain;">
            </td>
            <td style="padding:8px;width:80%;vertical-align:middle">
              <a href="https://arxiv.org/pdf/1708.08729">
                <span class="papertitle">Discovering gender differences in facial emotion recognition via implicit behavioral cues</span>
              </a>
              <br>
              <strong>Maneesh Bilalpur</strong>, Seyed Mostafa Kia, Tat-Seng Chua, and Ramanathan Subramanian
              <br>
              <em>IEEE ACII</em>, 2017
            </td>
          </tr>

          </tbody></table>

<!-- finish education and work experience -->
          <!-- <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
            <td style="padding:16px;width:100%;vertical-align:middle">
              <h2>Education</h2>
            </tr>
            </td>
            <td style="padding:16px;width:20%;vertical-align:middle">
              <img src="images/clean_promo.jpg" alt="clean-usnob" width="160" height="160">
            </td>
            <td style="padding:8px;width:80%;vertical-align:middle">
              <a href="https://arxiv.org/pdf/1708.08729">
                <span class="papertitle">Discovering gender differences in facial emotion recognition via implicit behavioral cues</span>
              </a>
              <br>
              <strong>Maneesh Bilalpur</strong>, Seyed Mostafa Kia, Tat-Seng Chua, Ramanathan Subramanian
              <br>
              <em>IEEE ACII</em>, 2017
            </td>
          </tbody></table>
        <table style="width:100%;border:0px;border-spacing:0px 10px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody> -->

<!-- ─────────────────────────────────────────────────────────────────────────── -->
<!-- 3) INTERNSHIPS SECTION -->
<!-- ─────────────────────────────────────────────────────────────────────────── -->
<table
  style="
    width: 100%;
    max-width: 800px;
    margin: 0 auto;
    border-spacing: 0;
    border-collapse: separate;
  "
>
  <tbody>
    <!-- Heading Row -->
    <tr>
      <td colspan="2" style="padding: 16px 0;">
        <h2>Work Experience</h2>
      </td>
    </tr>

    <!-- ───────────────────────────────────────────────────────────────────────── -->
    <!-- Playment -->
    <!-- ───────────────────────────────────────────────────────────────────────── -->
    <tr style="border-bottom: 1px solid #ddd;">
      <!-- Logo Cell -->
      <td
        style="
          padding: 8px;
          width: 20%;
          vertical-align: top;
        "
      >
        <!--
          Using the same Imperial logo as in Education, but you can supply a separate “imperial_logo.png” if you have one.
        -->
        <img
          src="images/playment_logo2.png"
          alt="Playment"
          style="
            width: 100%;
            max-width: 120px;
            object-fit: contain;
          "
        />
      </td>

      <!-- Text Cell -->
      <td
        style="
          padding: 8px;
          width: 80%;
          vertical-align: middle;
        "
      >
        <!-- Company + Department -->
        <p style="margin: 0; font-weight: bold; font-size: 1.1em;">
          Playment (acquired by Telus International)
        </p>

        <!-- Role, Mentor, Location, Dates -->
        <p style="margin: 2px 0;">
          <em>Computer Vision Researcher</em>
          <!--with
          
            Link “Maja Pantic” to her profile if you have the URL; otherwise use “#”.
          
          <a href="#" target="_blank">Prof. Maja Pantic</a>-->
          <br />
          Bengaluru, India
          &nbsp;&middot;&nbsp; Aug 2018 – Jul 2019
        </p>

        <!-- Description -->
        <p style="margin: 4px 0;">
          Developed and deployed interactive semantic segmentation models (including raster-to-vector conversion) to accelerate annotation. 
          Standardized 3D point clouds and implemented 3D→2D projections for a widely used annotation tool in self-driving applications. Shipped a GDPR-compliant anonymizer that automatically blurs faces and license plates.        </p>
      </td>
    </tr>

    <!-- ───────────────────────────────────────────────────────────────────────── -->
    <!-- Internship #3: National University of Singapore -->
    <!-- ───────────────────────────────────────────────────────────────────────── -->
    <tr>
      <!-- Logo Cell -->
      <td
        style="
          padding: 8px;
          width: 20%;
          vertical-align: top;
        "
      >
        <!--
          NUS logo (e.g. “nus_logo.png”). Replace with the actual file you have.
        -->
        <img
          src="images/nus_logo.svg"
          alt="National University of Singapore"
          style="
            width: 100%;
            max-width: 120px;
            object-fit: contain;
          "
        />
      </td>

      <!-- Text Cell -->
      <td
        style="
          padding: 8px;
          width: 80%;
          vertical-align: middle;
        "
      >
        <!-- Company + Department -->
        <p style="margin: 0; font-weight: bold; font-size: 1.1em;">
          National University of Singapore
        </p>

        <!-- Role, Mentor, Location, Dates -->
        <p style="margin: 2px 0;">
          <em>Research Intern</em>
          with
          <!--
            Link “Mohan Kankanhalli” to his profile if you have the URL; otherwise “#”.
          -->
          <a href="https://www.comp.nus.edu.sg/~mohan/">Prof. Mohan Kankanhalli</a>
          <br />
          Singapore
          &nbsp;&middot;&nbsp; Sep 2017 – May 2018
        </p>

        <!-- Description -->
        <p style="margin: 4px 0;">
          Worked on multimodal (EEG, and eye tracking) affect recognition from facial expression stimuli at the
          SeSaMe (Sensor Enhanced Social Media) Centre.
          Published at ICMI 2018.
        </p>
      </td>
    </tr>
  </tbody>
</table>


<!-- ──────────────────────────────────────────────────────────────────────── -->
<!-- 1) EDUCATION SECTION -->
<!-- ──────────────────────────────────────────────────────────────────────── -->
<table style="width:100%; max-width:800px; margin:0 auto; border-spacing:0; border-collapse:separate;">
  <tbody>
    <tr>
      <td colspan="2" style="padding:16px 0;">
        <h2>Education</h2>
      </td>
    </tr>

    <!-- Imperial College London -->
    <tr>
      <!-- Logo cell -->
      <td style="padding:8px; width:20%; vertical-align:top;">
        <!-- Make sure you have an institutional logo at images/imperial_logo.png (or update path) -->
        <img src="images/pitt_logo.png"
             alt="University of Pittsburgh"
             style="width:100%; max-width:120px; object-fit:contain;">
      </td>

      <!-- Text cell -->
      <td style="padding:8px; width:80%; vertical-align:middle;">
        <p style="margin:0; font-weight:bold; font-size:1.1em;">
          University of Pittsburgh
        </p>
        <p style="margin:2px 0;">
          <em>PhD in Intelligent Systems</em><br>
          Pittsburgh, United States&nbsp;&nbsp;&nbsp;·&nbsp;&nbsp;&nbsp;2019 – 2025
        </p>
        <!-- <p style="margin:2px 0; font-style:italic;"> -->
          <!-- Thesis title: “Learning Self-Supervised Representations of Audiovisual Human-Centric Data” -->
        <!-- </p> -->
      </td>
    </tr>

    <!-- Spacer row (optional) -->
    <tr><td colspan="2" style="height:16px;"></td></tr>

    <!-- IIIT Hyderabad -->
    <tr>
      <!-- Logo cell -->
      <td style="padding:8px; width:20%; vertical-align:top;">
        <!-- Make sure you have an institutional logo at images/iiit_logo.png (or update path) -->
        <img src="images/iiith_logo.png"
             alt="IIIT Hyderabad"
             style="width:100%; max-width:120px; object-fit:contain;">
      </td>

      <!-- Text cell -->
      <td style="padding:8px; width:80%; vertical-align:middle;">
        <p style="margin:0; font-weight:bold; font-size:1.1em;">
          IIIT Hyderabad
        </p>
        <p style="margin:2px 0;">
          <em>MS by Research in Electronics and Communication</em>&nbsp;&nbsp;&nbsp;·&nbsp;&nbsp;&nbsp;8.5 / 10.00<br>
          Hyderabad, India&nbsp;&nbsp;&nbsp;·&nbsp;&nbsp;&nbsp;2015 – 2018
        </p>
        <p style="margin:2px 0; font-style:italic;">
          Thesis: “Gender Differences in Facial Emotion Perception for User Profiling via Implicit Behavioral Signals”<br>
          Advised by Prof. Ramanathan Subramanian at the Center for Visual Information Technology
        </p>
      </td>
    </tr>

    <!-- VIT -->
    <tr>
      <!-- Logo cell -->
      <td style="padding:8px; width:20%; vertical-align:top;">
        <!-- Make sure you have an institutional logo at images/iiit_logo.png (or update path) -->
        <img src="images/vit_logo2.jpg"
             alt="VIT Velloew"
             style="width:100%; max-width:120px; object-fit:contain;">
      </td>

      <!-- Text cell -->
      <td style="padding:8px; width:80%; vertical-align:middle;">
        <p style="margin:0; font-weight:bold; font-size:1.1em;">
          VIT Vellore
        </p>
        <p style="margin:2px 0;">
          <em>Bachelors in Electronics and Communication</em>&nbsp;&nbsp;&nbsp;·&nbsp;&nbsp;&nbsp;8.98 / 10.00<br>
          Hyderabad, India&nbsp;&nbsp;&nbsp;·&nbsp;&nbsp;&nbsp;2011 – 2015
        </p>
      </td>
    </tr>

  </tbody>
</table>

<!-- ──────────────────────────────────────────────────────────────────────── -->
<!-- 2) AWARDS AND RECOGNITION SECTION -->
<!-- ──────────────────────────────────────────────────────────────────────── -->
<div style="width:100%; max-width:800px; margin:24px auto 0; padding:0 16px;">
  <h2>Awards and Recognition</h2>
  <ul style="margin-top:8px; padding-left:1.2em; line-height:1.5em;">
    <li>Provost's Dissertation Completion Fellowship for Fall 2025.</li>
    <li>Doctoral Consortium Travel Grant at FG 2025.</li>
    <li>Oustanding Reviewer Award at FG 2024.</li>
    <li>AAAI’24 student scholarship (visa prevented attendance).</li>
    <li>School of Computing and Information Fellow for Fall 2019.</li>
    <li>ACM SIGCHI Gary Marsden Student Development Fund (to attend ICMI 2018), 2018</li>
    <li>Student Travel Grant award winner for ACII’17 and ICMI’18.</li>
  </ul>
</div>

          
					<table style="width:100%; margin:0 auto; border:0; border-spacing:0; padding:16px;"><tbody>
            <tr>
              <td>
                <h2>Miscellanea</h2>
              </td>
            </tr>
          </tbody></table>
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            
           
            <!-- <tr>
              <td align="center" style="padding:16px;width:20%;vertical-align:middle">
						     <div class="colored-box" style="background-color: #fcb97d;">
								 <h2>Awards</h2>
								 </div>
              </td>
              <td style="padding:8px;width:80%;vertical-align:middle">
                <p>Provost's Dissertation Completion Fellowship for Fall 2025.</p>
                <p>Doctoral Consortium Travel Grant at FG 2025.</p>
                <p>Oustanding Reviewer Award at FG 2024.</p>
                <p>AAAI’24 student scholarship (visa prevented attendance).</p>
                <p>Student Travel Grant award winner for ACII’17 and ICMI’18.</p>
                <p>School of Computing and Information Fellow for Fall 2019.</p>

                <a href="https://arxiv.org/abs/2112.11687">Squareplus: A Softplus-Like Algebraic Rectifier</a>
                <br>
                <a href="https://arxiv.org/abs/2010.09714">A Convenient Generalization of Schlick's Bias and Gain Functions</a>
                <br>
                <a href="https://arxiv.org/abs/1704.07483">Continuously Differentiable Exponential Linear Units</a>
                <br>
                <a href="https://jonbarron.info/data/cvpr2023_llm_workshop_annotated.pdf">Scholars & Big Models: How Can Academics Adapt?</a> -->
              </td>
            </tr>


            <!-- <tr>
              <td align="center" style="padding:16px;width:20%;vertical-align:middle">
						     <div class="colored-box" style="background-color: #aaba9e;">
								 <h2>Recorded Talks</h2>
								 </div>
              </td>
              <td style="padding:8px;width:80%;vertical-align:center">
                <a href="https://www.youtube.com/watch?v=hFlF33JZbA0">Radiance Fields and the Future of Generative Media, 2025</a><br>				  
                <a href="https://www.youtube.com/watch?v=h9vq_65eDas">View Dependent Podcast, 2024</a><br>
                <a href="https://www.youtube.com/watch?v=4tDhYsFuEqo">Bay Area Robotics Symposium, 2023
</a><br>
                <a href="https://youtu.be/TvWkwDYtBP4?t=7604">EGSR Keynote, 2021</a><br>
				<a href="https://www.youtube.com/watch?v=nRyOzHpcr4Q">TUM AI Lecture Series, 2020</a><br>
				<a href="https://www.youtube.com/watch?v=HfJpQCBTqZs">Vision & Graphics Seminar at MIT, 2020</a>
              </td>
            </tr> -->

            <tr>
              <td align="center" style="padding:16px;width:20%;vertical-align:middle">
						     <div class="colored-box" style="background-color: #c6b89e;">
								 <h2>Academic Service</h2>
								 </div>
              </td>
              <td style="padding:8px;width:80%;vertical-align:center">
                <a href="https://ieeeichi2024.github.io/">Reviewer, IEEE International Conference on Healthcare Informatics 2024</a>
                <br>
                <a href="https://lrec-coling-2024.org/">Reviewer, LREC-COLING 2024</a>
                <br>
                <a href="https://ami4hc.stanford.edu/">PC member, Workshop on Ambient Intelligence for HealthCare, MICCAI 2023</a>
                <br>
                <a href="https://icmi.acm.org/2023/">Reviewer, ICMI 2023</a>
                <br>
                <a href="https://ieee-biometrics.org/conferences/flagship/fg/">Reviewer, Automatic Face & Gestures Recognition 2020, 2023-25</a>
                <br>
                <a href="https://ieee-biometrics.org/conferences/flagship/ijcb/">Reviewer, IJCB 2022-23</a>
                <br>
                <a href="https://www.computer.org/csdl/journal/ta">Reviewer, Transactions on Affective Computing</a>
                <br>
                <a href="https://ieeexplore.ieee.org/xpl/RecentIssue.jsp?punumber=6046">Reviewer, Transactions on Multimedia</a>
                <br>
                <a href="https://www.sciencedirect.com/journal/knowledge-based-systems">Reviewer, Knowledge-based Systems</a>
                <br>
                <a href="https://www.sciencedirect.com/journal/pattern-recognition">Reviewer, Pattern Recognition</a>
              </td>
            </tr>
						
						
           
            <tr>
              <td align="center" style="padding:16px;width:20%;vertical-align:middle">
						     <div class="colored-box" style="background-color: #edd892;">
								 <h2>Teaching</h2>
								 </div>
              </td>
              <td style="padding:8px;width:80%;vertical-align:center">
                <a href="https://ryanzshi.github.io/s25-cs2750.html">Teaching Assistant, CS 2750 Machine Learning (Spring 2025)</a>
                <br>
                <a href="https://scottjordan.github.io/courses/CS2078-F24/">Teaching Assistant, CS 1678/2078 Introduction to Deep Learning (Spring 2025)</a>
              </td>
            </tr>
            
          </tbody></table>
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
              <td style="padding:0px">
                <br>
                <p style="text-align:right;font-size:small;">
                  This website is an adaptation of <a href="https://github.com/jonbarron/jonbarron_website">Jon Barron's source code</a> and parts of templates borrowed from <a href="https://abhinav95.github.io/">Abhinav Shukla's website</a>.
                </p>
              </td>
            </tr>
          </tbody></table>
        </td>
      </tr>
    </table>
  </body>
</html>
